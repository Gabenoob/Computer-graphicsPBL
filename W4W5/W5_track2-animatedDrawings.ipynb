{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track 2 TODO 1:  Retrieve predicted segmentation mask and estimated joints from pretrained network\n",
    " \n",
    "For the first part of our animation pipeline, we will use the pretrained objection detection model and segmentation method from author's implementation to obtain a segmentation mask for our own drawing. Your first task is:\n",
    "1. Go to the Github repository https://github.com/facebookresearch/AnimatedDrawings/tree/main, follow the instructions in \"animating-your-own-drawing\" https://github.com/facebookresearch/AnimatedDrawings/tree/main#animating-your-own-drawing) to obtain a segmentation mask \"mask.png\", a texture map \"texture.png\", and locations of detected joint skeleton in \"char_cfg.yaml\" using the example drawing \"garlic.png\"\n",
    "2. Write code to load the segmentation mask and the original image, compose and visualize a masked image using Matplotlib\n",
    "3. Load detected joint locations, use Matplotlib to visualize the locations and labels of the joints. Visualize the tree hierarchy of the skeleton using lines (See desired output in session slide)\n",
    "4. Make your own drawing, and repeat step 1-3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track 2 TODO 2:  2D Mesh Generation using delaunay triangulation\n",
    "For the second part of our animation pipeline, we need to generate a 2D mesh from our masked image that we can use for rigging during the animation phase. Your task is\n",
    "1. Generate random points using Poisson Disk Sampling (https://medium.com/@hemalatha.psna/implementation-of-poisson-disc-sampling-in-javascript-17665e406ce1) as points in our mesh\n",
    "2. Use Delaunay triangulation to generate a 2D triangle mesh from sampled points\n",
    "3. Visualize the generated 2D mesh using Matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track 2 TODO 1: Render your generated 2D mesh with texture\n",
    "We are now ready to render our 2D mesh with a rendering engine (PyVista) using the generated 2D mesh. To do so,\n",
    "1. Output your generated 2D mesh into an obj format (https://en.wikipedia.org/wiki/Wavefront_.obj_file). Since our mesh is 2D, you can set the coordinate for z-axis to be 0. Make sure to include the computed texture coordinate for each triangle vertex, where the texture is the original drawing image. You can compute the texture coordinate for each vertex with pixel location $(p_x, p_y)$ using $ (p_x/width, p_y/height) $\n",
    "2. Load your obj file using the trimesh library's mesh = trimesh.load(file_path) function. You can then initialize a plotter object in PyVista using plotter = pyvista.Plotter(...). Load your drawing as a texture file, then use plotter.add_mesh(mesh, texture=...) (https://docs.pyvista.org/version/stable/api/plotting/_autosummary/pyvista.Plotter.add_mesh.html) to create a textured mesh.\n",
    "3. Visualize the textured mesh by calling plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track 2 TODO 2: Use As-Rigid-As-Possible to deform your mesh.\n",
    "Our animation pipeline will use the As-Rigid-As-Possible algorithm to animate our textured 2D mesh. You can reference Animated Drawing for an example implementation of the ARAP algorithm (https://github.com/facebookresearch/AnimatedDrawings/blob/main/animated_drawings/model/arap.py). \n",
    "1. Add ARAP to your pipeline, which allows you to supply as inputs the vertices to deform (vertices on your 2D textured mesh), handle locations (the detected joints for the drawing), target handle locations (target location for the joints) and output the positions for the deformed mesh.\n",
    "2. Modify the character joint location you loaded to create a new target pose, then use ARAP to compute the deformed mesh.\n",
    "3. Visualize the deformed mesh using the visualization pipeline you created in TODO 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
